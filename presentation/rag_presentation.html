<!DOCTYPE html>
<html lang="en"><head>
<script src="rag_presentation_files/libs/clipboard/clipboard.min.js"></script>
<script src="rag_presentation_files/libs/quarto-html/tabby.min.js"></script>
<script src="rag_presentation_files/libs/quarto-html/popper.min.js"></script>
<script src="rag_presentation_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="rag_presentation_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="rag_presentation_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="rag_presentation_files/libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.39">

  <meta name="author" content="Yuting Fan, Peng Li, Yiwei Qi">
  <meta name="dcterms.date" content="2024-12-10">
  <title>End-to-End Retrieval-Augmented Generation (RAG) System</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="rag_presentation_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="rag_presentation_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="rag_presentation_files/libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <link rel="stylesheet" href="styles.css">
  <link href="rag_presentation_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="rag_presentation_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="rag_presentation_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="rag_presentation_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="rag_presentation_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="rag_presentation_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">End-to-End Retrieval-Augmented Generation (RAG) System</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Yuting Fan, Peng Li, Yiwei Qi 
</div>
</div>
</div>

  <p class="date">2024-12-10</p>
</section>
<section>
<section id="introduction-system-overview" class="title-slide slide level1 center">
<h1>Introduction &amp; System Overview</h1>
<p>Speaker: Peng Li</p>
<aside class="notes">
<p>[1 min] Good afternoon, everyone. Today, we’ll be presenting our project on the End-to-End Retrieval-Augmented Generation (RAG) System. This project was developed by Yuting Fan, Peng Li, and Yiwei Qi for this DSAN 5800 course. Our goal is to create a scalable, efficient, and user-friendly system that integrates document retrieval with AI-generated responses. I’ll start by introducing the project and system overview, while my teammates will walk you through implementation, evaluation, and results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<p><strong>Prompt</strong>: <br> Give me details about the suspect of UnitedHealthcare CEO’s assassination that happended on Dec 4, 2024.</p>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center" style="width 100%">
<figure>
<p><img data-src="images/motivation1.png"></p>
<figcaption>Dec 8, 2024</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center" style="width 100%">
<figure>
<p><img data-src="images/motivation2.png"></p>
<figcaption>Dec 9, 2024</figcaption>
</figure>
</div>
</div><div class="column" style="width:20%;">
<p>Challenges:</p>
<ol type="1">
<li>No source</li>
<li>Out of date</li>
</ol>
</div></div>
</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li><strong>RAG Systems</strong>: Combine retrieval modules and generation modules for enhanced responses.</li>
<li><strong>Why it matters</strong>: Solves the issue of hallucination in generative AI by relying on factual document retrieval.</li>
</ul>
<p><a title="Turtlecrown, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:RAG_diagram.svg"><img width="400" alt="RAG diagram" src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/14/RAG_diagram.svg/512px-RAG_diagram.svg.png?20240716134738"></a></p>
<aside class="notes">
<p>[1 min] So, what is a RAG system? It stands for Retrieval-Augmented Generation. Unlike standard AI models that generate answers from internal knowledge, a RAG system retrieves relevant context from a document database and uses that context to produce accurate, fact-based responses. This makes it highly reliable and reduces hallucinations often seen in AI models. Our system supports dynamic document uploads, retrieval via FAISS, and generation using OpenAI’s GPT models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="system-goals" class="slide level2">
<h2>System Goals</h2>
<ul>
<li>Build a scalable, automated end-to-end RAG system.<br>
</li>
<li>To achieve:
<ul>
<li>High Retrieval Efficiency.</li>
<li>Accurate AI Responses.</li>
<li>Dynamic Knowledge Base Adaptability (with user uploads).</li>
</ul></li>
<li>Embed source information for transparency.</li>
</ul>
<aside class="notes">
<p>[1 min] Our main goal was to develop a system that automates the process of query handling, document retrieval, and AI-based response generation. By using FAISS for retrieval and OpenAI’s GPT for language generation, we achieved a fast, flexible, and transparent system. Additionally, we ensured that users can upload their own documents to expand the system’s knowledge base.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="system-architecture" class="slide level2">
<h2>System Architecture</h2>
<ol type="1">
<li>Document Retrieval Module
<ul>
<li><code>FAISS</code> for dense vector indexing and retrieval.<br>
</li>
<li>🤗 Hugging Face’s <code>SentenceTransformers</code> for embedding.<br>
</li>
</ul></li>
<li>Language Generation Module
<ul>
<li>OpenAI <code>GPT</code> models (GPT-3.5, GPT-4).<br>
</li>
<li>Contextual input creation from retrieved data.</li>
</ul></li>
<li>User Interface
<ul>
<li>Built <code>Streamlit</code> web app, supporting document upload, API key input, model selection.</li>
</ul></li>
</ol>
<aside class="notes">
<p>[1 min] Here’s the overall system architecture. It consists of three main modules: document retrieval, language generation, and user interface.</p>
<ol type="1">
<li>User Query <span class="math inline">\(\rightarrow\)</span> Vector Embedding<br>
</li>
<li><code>FAISS</code> Retrieval <span class="math inline">\(\rightarrow\)</span> Relevant Document Fragments<br>
</li>
<li><code>GPT</code> Integration <span class="math inline">\(\rightarrow\)</span> Contextual Response Generation<br>
</li>
<li><code>Streamlit</code> UI <span class="math inline">\(\rightarrow\)</span> Displays Response and Sources</li>
</ol>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- ### Data Flow
1. User Query $\rightarrow$ Vector Embedding  
2. `FAISS` Retrieval $\rightarrow$ Relevant Document Fragments  
3. `GPT` Integration $\rightarrow$ Contextual Response Generation  
4. `Streamlit` UI $\rightarrow$ Displays Response and Sources -->
<aside class="notes">
<p>[1 min] The process starts with a user query, which is converted into an embedding. The FAISS retriever searches for related documents, and those are combined with the query to generate a response using GPT. The answer is presented to the user in a simple interface built with Streamlit.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="implementation" class="title-slide slide level1 center">
<h1>Implementation</h1>
<p>Speaker: Yuting Fan</p>
</section>
<section id="implementation-details" class="slide level2">
<h2>Implementation Details</h2>
<h3 id="document-retrieval">Document Retrieval</h3>
<ul>
<li>Uses <code>FAISS</code> for dense vector-based search.</li>
<li>Embedding creation via <code>all-MiniLM-L6-v2</code> (Hugging Face’s SentenceTransformers).</li>
<li>Uses re-ranking with CrossEncoder to prioritize results.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="kw">class</span> DenseRetriever:</span>
<span id="cb1-2"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model_name<span class="op">=</span><span class="st">"all-MiniLM-L6-v2"</span>, reranker_model_name<span class="op">=</span><span class="st">"cross-encoder/ms-marco-MiniLM-L-12-v2"</span>):</span>
<span id="cb1-3"><a href=""></a>        <span class="va">self</span>.model <span class="op">=</span> SentenceTransformer(model_name)</span>
<span id="cb1-4"><a href=""></a>        <span class="va">self</span>.index <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-5"><a href=""></a>        <span class="va">self</span>.documents <span class="op">=</span> []</span>
<span id="cb1-6"><a href=""></a>        <span class="va">self</span>.reranker <span class="op">=</span> CrossEncoder(reranker_model_name)</span>
<span id="cb1-7"><a href=""></a></span>
<span id="cb1-8"><a href=""></a>    <span class="kw">def</span> build_index(<span class="va">self</span>, documents):</span>
<span id="cb1-9"><a href=""></a>        <span class="co">"""Build a FAISS index for the given documents."""</span></span>
<span id="cb1-10"><a href=""></a>        <span class="va">self</span>.documents <span class="op">=</span> documents</span>
<span id="cb1-11"><a href=""></a>        embeddings <span class="op">=</span> <span class="va">self</span>.model.encode(documents, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-12"><a href=""></a>        <span class="va">self</span>.index <span class="op">=</span> faiss.IndexFlatL2(embeddings.shape[<span class="dv">1</span>])</span>
<span id="cb1-13"><a href=""></a>        <span class="va">self</span>.index.add(embeddings)</span>
<span id="cb1-14"><a href=""></a></span>
<span id="cb1-15"><a href=""></a>    <span class="kw">def</span> retrieve(<span class="va">self</span>, query, k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb1-16"><a href=""></a>        <span class="co">"""Retrieve the top-k most relevant documents for a query using FAISS."""</span></span>
<span id="cb1-17"><a href=""></a>        query_vector <span class="op">=</span> <span class="va">self</span>.model.encode([query])</span>
<span id="cb1-18"><a href=""></a>        distances, indices <span class="op">=</span> <span class="va">self</span>.index.search(query_vector, k)</span>
<span id="cb1-19"><a href=""></a>        results <span class="op">=</span> [(<span class="va">self</span>.documents[i], distances[<span class="dv">0</span>][idx]) <span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(indices[<span class="dv">0</span>])]</span>
<span id="cb1-20"><a href=""></a>        <span class="cf">return</span> results</span>
<span id="cb1-21"><a href=""></a></span>
<span id="cb1-22"><a href=""></a>    <span class="kw">def</span> rerank(<span class="va">self</span>, query, retrieved_docs):</span>
<span id="cb1-23"><a href=""></a>        <span class="co">"""Re-rank the retrieved documents using a cross-encoder."""</span></span>
<span id="cb1-24"><a href=""></a>        pairs <span class="op">=</span> [(query, doc[<span class="dv">0</span>]) <span class="cf">for</span> doc <span class="kw">in</span> retrieved_docs]</span>
<span id="cb1-25"><a href=""></a>        scores <span class="op">=</span> <span class="va">self</span>.reranker.predict(pairs)</span>
<span id="cb1-26"><a href=""></a>        reranked <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">zip</span>(retrieved_docs, scores), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-27"><a href=""></a>        <span class="cf">return</span> [(doc[<span class="dv">0</span>], score) <span class="cf">for</span> doc, score <span class="kw">in</span> reranked]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>[1 min] Now let’s look at the system’s core technical implementation. For retrieval, we use FAISS, a vector search tool, combined with Hugging Face’s SentenceTransformers to create semantic embeddings.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="implementation-details-1" class="slide level2">
<h2>Implementation Details</h2>
<h3 id="language-generation">Language Generation</h3>
<ul>
<li>Supports user selection of GPT-3.5 or GPT-4.</li>
<li>Merges user queries with retrieved document content as context.</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="kw">class</span> RAGSystem:</span>
<span id="cb2-2"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, retriever):</span>
<span id="cb2-3"><a href=""></a>        <span class="va">self</span>.retriever <span class="op">=</span> retriever</span>
<span id="cb2-4"><a href=""></a></span>
<span id="cb2-5"><a href=""></a>    <span class="kw">def</span> generate_response(<span class="va">self</span>, query, model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>, k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb2-6"><a href=""></a>        <span class="co">"""Generate a response by combining retrieval and generation."""</span></span>
<span id="cb2-7"><a href=""></a>        <span class="cf">if</span> <span class="kw">not</span> openai.api_key:</span>
<span id="cb2-8"><a href=""></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"API key is not set. Please enter your OpenAI API key."</span>)</span>
<span id="cb2-9"><a href=""></a>        </span>
<span id="cb2-10"><a href=""></a>        retrieved_docs <span class="op">=</span> <span class="va">self</span>.retriever.retrieve(query, k)</span>
<span id="cb2-11"><a href=""></a>        reranked_docs <span class="op">=</span> <span class="va">self</span>.retriever.rerank(query, retrieved_docs)</span>
<span id="cb2-12"><a href=""></a>        context <span class="op">=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join([<span class="ss">f"</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">. </span><span class="sc">{</span>doc<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i, (doc, _) <span class="kw">in</span> <span class="bu">enumerate</span>(reranked_docs)])</span>
<span id="cb2-13"><a href=""></a>        prompt <span class="op">=</span> (</span>
<span id="cb2-14"><a href=""></a>            <span class="ss">f"Contextual documents:</span><span class="ch">\n</span><span class="sc">{</span>context<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb2-15"><a href=""></a>            <span class="ss">f"Query: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb2-16"><a href=""></a>            <span class="ss">f"Response:"</span></span>
<span id="cb2-17"><a href=""></a>        )</span>
<span id="cb2-18"><a href=""></a>        response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb2-19"><a href=""></a>            model<span class="op">=</span>model_name, <span class="co"># change model based on user selection</span></span>
<span id="cb2-20"><a href=""></a>            messages<span class="op">=</span>[</span>
<span id="cb2-21"><a href=""></a>                {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are a helpful assistant."</span>},</span>
<span id="cb2-22"><a href=""></a>                {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}</span>
<span id="cb2-23"><a href=""></a>            ],</span>
<span id="cb2-24"><a href=""></a>            max_tokens<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb2-25"><a href=""></a>        )</span>
<span id="cb2-26"><a href=""></a>        <span class="cf">return</span> response[<span class="st">'choices'</span>][<span class="dv">0</span>][<span class="st">'message'</span>][<span class="st">'content'</span>].strip(), reranked_docs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>[1 min] For generation, we use OpenAI’s GPT models, with users having the option to select GPT-3.5 or GPT-4. The user input is combined with document content to generate accurate and relevant responses.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="implementation-details-2" class="slide level2">
<h2>Implementation Details</h2>
<h3 id="user-interface">User Interface</h3>
<div class="columns">
<div class="column" style="width:65%;">
<p><img data-src="images/UI.png" style="width 100%"></p>
</div><div class="column" style="width:35%;">
<ul>
<li>Real-time Document Upload</li>
<li>Multiple GPT Models</li>
<li>Retrieval Transparency</li>
<li><a href="https://yuting-fan-265-rag-system-rag-app-new-v1sxnc.streamlit.app">Link</a></li>
</ul>
</div></div>
<aside class="notes">
<p>[1 min] We’ve also made the system easy to use. The user interface is built with Streamlit, allowing users to upload custom documents and select which GPT model they want to use. This allows for real-time responses and makes it easy to expand the knowledge base on demand.</p>
<p>[<em>Give a demo about how to use the system</em>]</p>
<p>[2 min] Some key features of our system include real-time document uploads, support for multiple GPT models, and transparency. The system displays which document it retrieved information from, providing credibility and context for users.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>

<img data-src="images/example1.png" class="quarto-figure quarto-figure-center r-stretch" style="width: 100%"></section>
<section id="example-1" class="slide level2">
<h2>Example</h2>

<img data-src="images/example2.png" class="quarto-figure quarto-figure-center r-stretch" style="width: 100%"></section>
<section id="example-2" class="slide level2">
<h2>Example</h2>

<img data-src="images/example3.png" class="quarto-figure quarto-figure-center r-stretch" style="width: 100%"></section></section>
<section>
<section id="evaluation-conclusion" class="title-slide slide level1 center">
<h1>Evaluation &amp; Conclusion</h1>
<p>Speaker: Yiwei Qi</p>
</section>
<section id="evaluation" class="slide level2">
<h2>Evaluation</h2>
<h3 id="key-tests-conducted">Key Tests Conducted</h3>
<ol type="1">
<li>File Type Support: <em>PDF</em>, <em>DOCX</em>, <em>TXT</em>.<br>
</li>
<li>File Size:
<ul>
<li>Handles small files efficiently.<br>
</li>
<li>Large files (&gt;100MB) processed in segments.<br>
</li>
<li>Extremely large files (&gt;1GB) may require stream processing.</li>
</ul></li>
</ol>
<aside class="notes">
<p>We conducted comprehensive tests on the Search Enhanced Generation (RAG) system to verify its compatibility with different file types, sizes, and formats. These tests evaluate the system’s ability to handle large files and its robustness against invalid file contents and queries. The goal is to ensure stable performance, efficiency, and clear error feedback in case of user input issues.</p>
<p>We tested mainstream file types (PDF, PNG, HTML, TSV, JPG, etc.) to verify system compatibility, finding that the system supports text-based files like PDFs but cannot process binary files (e.g., .dmg, .pkg) or files lacking natural language text. In the file size test, small files (&lt;1KB) processed quickly, while larger files (&gt;100MB) were handled using batch processing, though query speed decreased as the file size approached memory limits. For very large files (&gt;1GB), memory issues occurred during preprocessing, highlighting the need for a stream processing mechanism.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="evaluation-1" class="slide level2">
<h2>Evaluation</h2>
<h3 id="key-tests-conducted-1">Key Tests Conducted</h3>
<ol start="3" type="1">
<li>Invalid Content: Handles empty or garbled files with appropriate feedback.<br>
</li>
<li>Query Robustness: Handles random or malformed queries gracefully.</li>
</ol>

<img data-src="images/invalid_files.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>In the invalid file content test, the system accurately detects empty files (e.g., Doc.docx) and provides a clear error message, while it struggles to generate meaningful embeddings for garbled files (e.g., well.docx) but still provides feedback to the user.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="query-validation" class="slide level2">
<h2>Query Validation</h2>

<img data-src="images/query-validation.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>For the query validity test, the system handles invalid queries (e.g., random characters) by returning “No matching content found” when no relevant documents are found. In cases of empty queries, the system blocks execution and prompts users to enter valid questions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="performance-analysis" class="slide level2">
<h2>Performance Analysis</h2>
<h3 id="gpt-3.5-vs.-gpt-4">GPT-3.5 vs.&nbsp;GPT-4</h3>
<table class="caption-top">
<colgroup>
<col style="width: 35%">
<col style="width: 32%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Criterion</strong></th>
<th>GPT-4</th>
<th>GPT-3.5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Accuracy</strong></td>
<td>Higher</td>
<td>Lower</td>
</tr>
<tr class="even">
<td><strong>Context Relevance</strong></td>
<td>Stronger Context Understanding</td>
<td>Generalized Responses</td>
</tr>
<tr class="odd">
<td><strong>Detail Quality</strong></td>
<td>More detailed</td>
<td>Less specific</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>In terms of accuracy, GPT-4.0 outperforms GPT-3.5-Turbo by clearly extracting and summarizing key information from documents, such as experimental results and research contributions, with better alignment to the original content. GPT-4.0 also demonstrates superior semantic relevance, offering more logical, targeted, and coherent answers to complex queries, while GPT-3.5-Turbo’s responses are slightly less detailed and sometimes miss important points.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>Successfully implemented a dynamic, scalable RAG system.<br>
</li>
<li>Key Takeaways:
<ul>
<li>Efficient retrieval, accurate generation.<br>
</li>
<li>Transparency with source embedding.<br>
</li>
</ul></li>
<li>Future Scope:
<ul>
<li>Support for multi-modal data (images, audio, video).<br>
</li>
<li>Fine-tuning GPT for specific domains.</li>
</ul></li>
</ul>
<aside class="notes">
<p>In conclusion, We have successfully implemented an end-to-end Retrieval Augmented Generation (RAG) system that combines efficient FAISS-based retrieval with GPT for accurate, fast answers and supports document uploading and source tracing for interpretability. The system allows users to connect their OpenAI accounts and choose different language models for personalized performance, while also offering scalability to meet diverse needs. Future improvements include extending support for multi-modal data (e.g., images, audio, video) and fine-tuning GPT with domain-specific datasets to enhance accuracy, enabling broader applications in fields like intelligent question answering and cross-modal knowledge management.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section id="thank-you" class="title-slide slide level1 center">
<h1>Thank you!</h1>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="images/gu_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>DSAN5800 Project: RAG System</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="rag_presentation_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="rag_presentation_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="rag_presentation_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="rag_presentation_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>